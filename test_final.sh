#!/bin/bash

# =============================================================================
# TESTE DIRETO NO CONTAINER - SEM ENTRYPOINT
# =============================================================================

echo "ğŸ” TESTE DE DETECÃ‡ÃƒO - BYPASS ENTRYPOINT"
echo "========================================"
echo

# Verificar Docker Compose
DOCKER_COMPOSE_CMD=""
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE_CMD="docker-compose"
elif docker compose version &> /dev/null 2>&1; then
    DOCKER_COMPOSE_CMD="docker compose"
else
    echo "âŒ Docker Compose nÃ£o encontrado!"
    exit 1
fi

if [[ ! -f .env ]]; then
    echo "âŒ Arquivo .env nÃ£o encontrado!"
    exit 1
fi

echo "âœ… ConfiguraÃ§Ãµes encontradas"
echo

# Usar --entrypoint para bypass do entrypoint personalizado
echo "ğŸš€ Executando anÃ¡lise direta no container..."
echo

echo "ğŸ“Š 1. Testando conexÃ£o..."
$DOCKER_COMPOSE_CMD run --rm --entrypoint="" mariadb-backup bash -c '
source /app/entrypoint.sh > /dev/null 2>&1 || true
mysql -h"$SOURCE_HOST" -P"$SOURCE_PORT" -u"$DB_USERNAME" -p"$DB_PASSWORD" -e "SELECT \"âœ… ConexÃ£o OK\" as status;" 2>/dev/null
'

echo
echo "ğŸ“‹ 2. Listando tabelas por tamanho..."
$DOCKER_COMPOSE_CMD run --rm --entrypoint="" mariadb-backup bash -c '
source /app/entrypoint.sh > /dev/null 2>&1 || true
mysql -h"$SOURCE_HOST" -P"$SOURCE_PORT" -u"$DB_USERNAME" -p"$DB_PASSWORD" -e "
SELECT 
    table_name as \"ğŸ“Š Tabela\",
    FORMAT(table_rows, 0) as \"ğŸ“ Registros\",
    CONCAT(ROUND((data_length + index_length) / 1024 / 1024, 1), \" MB\") as \"ğŸ’¾ Tamanho\"
FROM information_schema.tables 
WHERE table_schema = \"$DATABASES\" 
ORDER BY (data_length + index_length) DESC
LIMIT 10;
" 2>/dev/null
'

echo
echo "ğŸ” 3. Detectando tabelas grandes..."
$DOCKER_COMPOSE_CMD run --rm --entrypoint="" mariadb-backup bash -c '
source /app/entrypoint.sh > /dev/null 2>&1 || true

echo "âš™ï¸  ConfiguraÃ§Ãµes:"
echo "   Limite: ${CHUNK_SIZE_THRESHOLD_MB:-1000}MB"
echo "   Chunk size: ${CHUNK_SIZE:-50000} registros"
echo "   Timeout/chunk: $((${CHUNK_TIMEOUT:-1800}/60)) minutos"
echo

# Buscar tabelas grandes
large_tables=$(mysql -h"$SOURCE_HOST" -P"$SOURCE_PORT" -u"$DB_USERNAME" -p"$DB_PASSWORD" -BN -e "
SELECT CONCAT(table_name, \":\", ROUND((data_length + index_length) / 1024 / 1024, 1), \":\", IFNULL(table_rows, 0))
FROM information_schema.tables 
WHERE table_schema = \"$DATABASES\" 
AND (data_length + index_length) > (${CHUNK_SIZE_THRESHOLD_MB:-1000} * 1024 * 1024)
ORDER BY (data_length + index_length) DESC;
" 2>/dev/null)

if [[ -n "$large_tables" ]]; then
    echo "âš¡ TABELAS GRANDES DETECTADAS!"
    echo
    echo "ğŸ¯ ESTRATÃ‰GIA: BACKUP HÃBRIDO"
    echo "   âœ… Tabelas grandes: processadas por chunks"
    echo "   âœ… Tabelas pequenas: backup tradicional"
    echo "   âœ… Resultado: arquivo Ãºnico consolidado"
    echo
    
    total_chunks=0
    total_time_min=0
    
    echo "ğŸ”§ ANÃLISE DETALHADA:"
    while IFS=":" read -r table_name size_mb table_rows; do
        if [[ $table_rows -gt 0 ]]; then
            chunks=$((($table_rows + ${CHUNK_SIZE:-50000} - 1) / ${CHUNK_SIZE:-50000}))
        else
            chunks=1
        fi
        total_chunks=$((total_chunks + chunks))
        time_min=$((chunks * ${CHUNK_TIMEOUT:-1800} / 60))
        total_time_min=$((total_time_min + time_min))
        
        echo
        echo "   ğŸ“Š $table_name"
        echo "      ğŸ’¾ Tamanho: ${size_mb}MB"
        echo "      ğŸ“ Registros: $(printf \"%'"'"'d\" $table_rows)"
        echo "      ğŸ“¦ Chunks: $chunks"
        echo "      â° Tempo: ${time_min}min (~$((time_min/60))h)"
        
    done <<< "$large_tables"
    
    total_hours=$((total_time_min / 60))
    
    echo
    echo "ğŸ“ˆ RESUMO FINAL:"
    echo "   ğŸ”¢ Total de chunks: $total_chunks"
    echo "   â³ Tempo total estimado: ${total_hours}h ${total_time_min}min"
    
    echo
    if [[ $total_hours -gt 48 ]]; then
        echo "âš ï¸  RECOMENDAÃ‡Ã•ES (tempo muito longo):"
        echo "   - CHUNK_SIZE=100000 (reduz chunks pela metade)"
        echo "   - CHUNK_TIMEOUT=3600 (1h por chunk)"
        echo "   - Executar em final de semana"
    elif [[ $total_hours -gt 24 ]]; then
        echo "ğŸ’¡ RECOMENDAÃ‡Ã•ES (tempo considerÃ¡vel):"
        echo "   - CHUNK_SIZE=75000 (reduz chunks)"
        echo "   - Executar em horÃ¡rio de baixo uso"
    else
        echo "âœ… CONFIGURAÃ‡Ã•ES ADEQUADAS"
        echo "   - Tempo aceitÃ¡vel para execuÃ§Ã£o"
    fi
    
else
    echo "â„¹ï¸  NENHUMA TABELA > ${CHUNK_SIZE_THRESHOLD_MB:-1000}MB"
    echo
    echo "ğŸ¯ ESTRATÃ‰GIA: BACKUP TRADICIONAL"
    echo "   âœ… Todas as tabelas: mysqldump padrÃ£o"
    echo "   âœ… Tempo estimado: < 30min"
fi
'

echo
echo "ğŸ‰ ANÃLISE CONCLUÃDA!"
echo
echo "ğŸš€ AÃ‡Ã•ES RECOMENDADAS:"
echo "   1. âœ… Revisar anÃ¡lise acima"
echo "   2. ğŸ”§ Ajustar .env se necessÃ¡rio"
echo "   3. ğŸš€ Executar: docker compose up"
echo "   4. ğŸ“Š Monitorar: tail -f logs/backup.log"
