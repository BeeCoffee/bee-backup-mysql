# =============================================================================
# CONFIGURA√á√ÉO ESPEC√çFICA PARA BANCOS GRANDES (200GB+)
# =============================================================================
# Este arquivo de exemplo √© otimizado para:
# - Bancos de dados com mais de 200GB
# - Tabelas individuais entre 30GB e 80GB
# - Ambientes de produ√ß√£o com zero locks
# - Backup com chunks autom√°ticos para tabelas grandes

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES DOS SERVIDORES DE BANCO DE DADOS
# -----------------------------------------------------------------------------

# Servidor de origem (onde est√£o os dados para backup)
SOURCE_HOST=127.0.0.1
SOURCE_PORT=53306

# Servidor de destino (onde os backups ser√£o restaurados)
DEST_HOST=127.0.0.1
DEST_PORT=3306

# Credenciais de acesso aos bancos de dados
DB_USERNAME=seu_usuario
DB_PASSWORD=sua_senha

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES DE BACKUP PARA BANCOS GRANDES
# -----------------------------------------------------------------------------

# Databases a serem inclu√≠dos no backup (separados por v√≠rgula)
DATABASES=seu_database

# Agendamento do backup - Para bancos grandes, executar com menos frequ√™ncia
# Sugest√£o: 1x por dia durante madrugada (menos carga no servidor)
BACKUP_TIME="0 2 * * *"

# Reten√ß√£o mais longa para bancos grandes (recupera√ß√£o √© mais demorada)
RETENTION_DAYS=14

# SEMPRE ativar compress√£o para bancos grandes (economiza 60-80% do espa√ßo)
BACKUP_COMPRESSION=true

# Prefixo dos arquivos de backup
BACKUP_PREFIX=backup_large

# -----------------------------------------------------------------------------
# OP√á√ïES MYSQL OTIMIZADAS PARA BANCOS GRANDES - ZERO LOCKS
# -----------------------------------------------------------------------------

# MYSQLDUMP com zero locks e otimiza√ß√µes para tabelas grandes
MYSQLDUMP_OPTIONS="--single-transaction --quick --lock-tables=false --no-tablespaces --skip-lock-tables --skip-add-locks --routines --triggers --default-character-set=utf8mb4 --max_allowed_packet=2G --net_buffer_length=32K --extended-insert --disable-keys"

# Cliente MySQL otimizado para conex√µes longas
MYSQL_CLIENT_OPTIONS="--max_allowed_packet=2G --net_buffer_length=32K --connect_timeout=120"

# N√£o executar backup na inicializa√ß√£o (muito pesado)
RUN_ON_START=false

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES DE SISTEMA PARA BANCOS GRANDES
# -----------------------------------------------------------------------------

# Timezone do sistema
TZ=America/Sao_Paulo

# SEMPRE usar logs detalhados para monitoramento
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES DE PERFORMANCE PARA BANCOS GRANDES
# -----------------------------------------------------------------------------

# Timeout muito alto para opera√ß√µes longas (6 horas)
DB_TIMEOUT=21600

# Muitas tentativas para maior robustez
MAX_RETRY_ATTEMPTS=7

# Intervalo maior entre tentativas (recupera√ß√£o de falhas)
RETRY_INTERVAL=60

# SEMPRE ativar logs detalhados para bancos grandes
ENABLE_DEBUG_LOGS=true

# SEMPRE verificar integridade (cr√≠tico para backups grandes)
VERIFY_BACKUP_INTEGRITY=true

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES CR√çTICAS PARA CHUNKING DE TABELAS GRANDES
# -----------------------------------------------------------------------------
# ‚ö° CONFIGURA√á√ÉO ESPEC√çFICA PARA TABELAS DE 30-80GB

# SEMPRE ativar chunking para bancos grandes
ENABLE_AUTO_CHUNKING=true

# Detectar tabelas maiores que 500MB para chunking
# Para tabelas de 30-80GB, todas ser√£o processadas em chunks
CHUNK_SIZE_THRESHOLD_MB=500

# Tamanho otimizado para tabelas de 30-80GB
# 50000 registros = bom equil√≠brio entre velocidade e estabilidade
CHUNK_SIZE=50000

# Timeout generoso para cada chunk (45 minutos)
# Tabelas grandes podem ter chunks que demoram muito
CHUNK_TIMEOUT=2700

# Muitas tentativas para chunks (ambiente produ√ß√£o)
CHUNK_MAX_RETRIES=5

# Pausa pequena entre chunks para n√£o sobrecarregar
CHUNK_INTERVAL_MS=200

# -----------------------------------------------------------------------------
# NOTIFICA√á√ïES POR EMAIL (CR√çTICAS PARA BANCOS GRANDES)
# -----------------------------------------------------------------------------

# SEMPRE ativar notifica√ß√µes para monitorar backups longos
ENABLE_EMAIL_NOTIFICATIONS=true

# Configura√ß√µes do email
EMAIL_FROM=backup@suaempresa.com
EMAIL_TO=admin@suaempresa.com,dba@suaempresa.com
EMAIL_SUBJECT_PREFIX=[BACKUP-LARGE-DB]

# Configura√ß√µes do servidor SMTP
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=backup@suaempresa.com
SMTP_PASSWORD=sua_senha_smtp

# Usar TLS/SSL
SMTP_USE_TLS=true

# -----------------------------------------------------------------------------
# CONFIGURA√á√ïES DE WEBHOOK (OPCIONAL)
# -----------------------------------------------------------------------------

# URL do webhook para notifica√ß√µes em tempo real
WEBHOOK_URL=https://hooks.slack.com/seu-webhook

# Nome do webhook
WEBHOOK_USERNAME="Backup Sistema Grande"

# =============================================================================
# ESTIMATIVAS DE TEMPO PARA BANCOS GRANDES
# =============================================================================
# 
# Com essas configura√ß√µes, para um banco de 200GB com tabela de 80GB:
# 
# üïê Tempo estimado total: 8-12 horas
# üìä Chunks gerados: ~400-500 (tabela 80GB)
# üíæ Espa√ßo em disco necess√°rio: ~60GB (com compress√£o)
# üîÑ Restaura√ß√£o: 4-6 horas
# 
# üí° DICAS IMPORTANTES:
# - Execute durante madrugada para menor impacto
# - Monitore logs em /logs/backup.log
# - Verifique espa√ßo em disco antes do backup
# - Teste a restaura√ß√£o em ambiente n√£o-produ√ß√£o
# - Configure alertas para falhas de backup
#
# =============================================================================
